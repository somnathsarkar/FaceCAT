{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Prediction on LFW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Dense,Dropout,Activation,Flatten,BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import svm\n",
    "import glob\n",
    "import h5py\n",
    "import cv2\n",
    "from tqdm import trange,tqdm\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "train_size = 10000\n",
    "filelist = np.array(glob.glob(\"../Data/lfw-deepfunneled/**/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lfwdf = pd.read_csv(\"../Data/lfw_attributes.txt\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>imagenum</th>\n",
       "      <th>Male</th>\n",
       "      <th>Asian</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Baby</th>\n",
       "      <th>Child</th>\n",
       "      <th>Youth</th>\n",
       "      <th>Middle Aged</th>\n",
       "      <th>...</th>\n",
       "      <th>5 o' Clock Shadow</th>\n",
       "      <th>Strong Nose-Mouth Lines</th>\n",
       "      <th>Wearing Lipstick</th>\n",
       "      <th>Flushed Face</th>\n",
       "      <th>High Cheekbones</th>\n",
       "      <th>Brown Eyes</th>\n",
       "      <th>Wearing Earrings</th>\n",
       "      <th>Wearing Necktie</th>\n",
       "      <th>Wearing Necklace</th>\n",
       "      <th>merger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Eckhart</td>\n",
       "      <td>1</td>\n",
       "      <td>1.568346</td>\n",
       "      <td>-1.889043</td>\n",
       "      <td>1.737203</td>\n",
       "      <td>-0.929729</td>\n",
       "      <td>-1.471799</td>\n",
       "      <td>-0.195580</td>\n",
       "      <td>-0.835609</td>\n",
       "      <td>-0.351468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166118</td>\n",
       "      <td>-1.164916</td>\n",
       "      <td>-1.139990</td>\n",
       "      <td>-2.371746</td>\n",
       "      <td>-1.299932</td>\n",
       "      <td>-0.414682</td>\n",
       "      <td>-1.144902</td>\n",
       "      <td>0.694007</td>\n",
       "      <td>-0.826609</td>\n",
       "      <td>../Data/lfw-deepfunneled\\Aaron_Eckhart\\Aaron_E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Guiel</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169851</td>\n",
       "      <td>-0.982408</td>\n",
       "      <td>0.422709</td>\n",
       "      <td>-1.282184</td>\n",
       "      <td>-1.360060</td>\n",
       "      <td>-0.867002</td>\n",
       "      <td>-0.452293</td>\n",
       "      <td>-0.197521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397680</td>\n",
       "      <td>0.874160</td>\n",
       "      <td>-0.945431</td>\n",
       "      <td>-0.268649</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>-0.030406</td>\n",
       "      <td>-0.480128</td>\n",
       "      <td>0.666760</td>\n",
       "      <td>-0.496559</td>\n",
       "      <td>../Data/lfw-deepfunneled\\Aaron_Guiel\\Aaron_Gui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Patterson</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997749</td>\n",
       "      <td>-1.364195</td>\n",
       "      <td>-0.157377</td>\n",
       "      <td>-0.756447</td>\n",
       "      <td>-1.891825</td>\n",
       "      <td>-0.871526</td>\n",
       "      <td>-0.862893</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.884745</td>\n",
       "      <td>-0.999765</td>\n",
       "      <td>-1.359858</td>\n",
       "      <td>-1.912108</td>\n",
       "      <td>-1.095634</td>\n",
       "      <td>0.915126</td>\n",
       "      <td>-0.572332</td>\n",
       "      <td>0.144262</td>\n",
       "      <td>-0.841231</td>\n",
       "      <td>../Data/lfw-deepfunneled\\Aaron_Patterson\\Aaron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Peirsol</td>\n",
       "      <td>1</td>\n",
       "      <td>1.122719</td>\n",
       "      <td>-1.997799</td>\n",
       "      <td>1.916144</td>\n",
       "      <td>-2.514214</td>\n",
       "      <td>-2.580071</td>\n",
       "      <td>-1.404239</td>\n",
       "      <td>0.057551</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176089</td>\n",
       "      <td>1.108125</td>\n",
       "      <td>-1.600944</td>\n",
       "      <td>-3.264613</td>\n",
       "      <td>0.813418</td>\n",
       "      <td>0.308631</td>\n",
       "      <td>-0.848693</td>\n",
       "      <td>0.475941</td>\n",
       "      <td>-0.447025</td>\n",
       "      <td>../Data/lfw-deepfunneled\\Aaron_Peirsol\\Aaron_P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Peirsol</td>\n",
       "      <td>2</td>\n",
       "      <td>1.078214</td>\n",
       "      <td>-2.008098</td>\n",
       "      <td>1.676211</td>\n",
       "      <td>-2.278056</td>\n",
       "      <td>-2.651845</td>\n",
       "      <td>-1.348408</td>\n",
       "      <td>0.649089</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.955283</td>\n",
       "      <td>0.119113</td>\n",
       "      <td>-1.128176</td>\n",
       "      <td>-3.161048</td>\n",
       "      <td>0.082680</td>\n",
       "      <td>-0.439614</td>\n",
       "      <td>-0.359859</td>\n",
       "      <td>-0.760774</td>\n",
       "      <td>-0.410152</td>\n",
       "      <td>../Data/lfw-deepfunneled\\Aaron_Peirsol\\Aaron_P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            person  imagenum      Male     Asian     White     Black  \\\n",
       "0    Aaron Eckhart         1  1.568346 -1.889043  1.737203 -0.929729   \n",
       "1      Aaron Guiel         1  0.169851 -0.982408  0.422709 -1.282184   \n",
       "2  Aaron Patterson         1  0.997749 -1.364195 -0.157377 -0.756447   \n",
       "3    Aaron Peirsol         1  1.122719 -1.997799  1.916144 -2.514214   \n",
       "4    Aaron Peirsol         2  1.078214 -2.008098  1.676211 -2.278056   \n",
       "\n",
       "       Baby     Child     Youth  Middle Aged  \\\n",
       "0 -1.471799 -0.195580 -0.835609    -0.351468   \n",
       "1 -1.360060 -0.867002 -0.452293    -0.197521   \n",
       "2 -1.891825 -0.871526 -0.862893     0.031445   \n",
       "3 -2.580071 -1.404239  0.057551     0.000196   \n",
       "4 -2.651845 -1.348408  0.649089     0.017656   \n",
       "\n",
       "                         ...                          5 o' Clock Shadow  \\\n",
       "0                        ...                                   1.166118   \n",
       "1                        ...                                  -0.397680   \n",
       "2                        ...                                   1.884745   \n",
       "3                        ...                                  -0.176089   \n",
       "4                        ...                                  -0.955283   \n",
       "\n",
       "   Strong Nose-Mouth Lines  Wearing Lipstick  Flushed Face  High Cheekbones  \\\n",
       "0                -1.164916         -1.139990     -2.371746        -1.299932   \n",
       "1                 0.874160         -0.945431     -0.268649        -0.006244   \n",
       "2                -0.999765         -1.359858     -1.912108        -1.095634   \n",
       "3                 1.108125         -1.600944     -3.264613         0.813418   \n",
       "4                 0.119113         -1.128176     -3.161048         0.082680   \n",
       "\n",
       "   Brown Eyes  Wearing Earrings  Wearing Necktie  Wearing Necklace  \\\n",
       "0   -0.414682         -1.144902         0.694007         -0.826609   \n",
       "1   -0.030406         -0.480128         0.666760         -0.496559   \n",
       "2    0.915126         -0.572332         0.144262         -0.841231   \n",
       "3    0.308631         -0.848693         0.475941         -0.447025   \n",
       "4   -0.439614         -0.359859        -0.760774         -0.410152   \n",
       "\n",
       "                                              merger  \n",
       "0  ../Data/lfw-deepfunneled\\Aaron_Eckhart\\Aaron_E...  \n",
       "1  ../Data/lfw-deepfunneled\\Aaron_Guiel\\Aaron_Gui...  \n",
       "2  ../Data/lfw-deepfunneled\\Aaron_Patterson\\Aaron...  \n",
       "3  ../Data/lfw-deepfunneled\\Aaron_Peirsol\\Aaron_P...  \n",
       "4  ../Data/lfw-deepfunneled\\Aaron_Peirsol\\Aaron_P...  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zippy = np.array(list(zip(lfwdf[\"person\"].values,lfwdf[\"imagenum\"].values)))\n",
    "zippy = [[i[0].replace(' ','_'),\"{}_{:04d}\".format(i[0].replace(' ','_'),int(i[1]))] for i in zippy]\n",
    "zippy = np.array([\"../Data/lfw-deepfunneled\\\\{}\\\\{}.jpg\".format(i[0],i[1]) for i in zippy])\n",
    "lfwdf = lfwdf.assign(merger=zippy)\n",
    "filelist = pd.DataFrame(filelist)\n",
    "lfwdf = lfwdf.merge(filelist,left_on=[\"merger\"],right_on=filelist.columns[0],copy=False)\n",
    "lfwdf.drop(lfwdf.columns[-1],axis=1,inplace=True)\n",
    "lfwdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    if(img.shape[0]!=img.shape[1]):\n",
    "        img = img[25:225,25:225]\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    img = ((img.astype(float).reshape(64,64,1))/255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size,step,start_index=0,end_index=train_size):\n",
    "    i = step\n",
    "    si = start_index+(i*batch_size)\n",
    "    ei = start_index+((i+1)*batch_size)\n",
    "    X = []\n",
    "    for j in range(si,ei):\n",
    "        X.append(get_image(lfwdf[\"merger\"][j]))\n",
    "    X = np.array(X)\n",
    "    y = lfwdf[[\"Baby\",\"Child\",\"Youth\",\"Middle Aged\",\"Senior\"]][si:ei].values\n",
    "    for j in range(y.shape[0]):\n",
    "        max_cmp = max(y[j])\n",
    "        onehot = [1 if yj == max_cmp else 0 for yj in y[j]]\n",
    "        y[j]=onehot\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32768)             131072    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 35,037,157\n",
      "Trainable params: 34,966,885\n",
      "Non-trainable params: 70,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,1),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7023\tAcc: 0.3538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312/312 [04:14<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3032\tAcc: 0.4806: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312/312 [04:11<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2257\tAcc: 0.5056:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 204/312 [02:39<01:24,  1.28it/s]"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(num_epochs):\n",
    "    print(\"Epoch {}\".format(epoch_i+1))\n",
    "    loss_avg = 0.0\n",
    "    acc_avg = 0.0\n",
    "    step = 0\n",
    "    last_step = 0\n",
    "    num_steps = train_size//batch_size\n",
    "    trng = tqdm(range(num_steps),total=num_steps)\n",
    "    for i in trng:\n",
    "        X,y = get_batch(batch_size,i)\n",
    "        loss,acc = model.train_on_batch(X,y)\n",
    "        loss_avg+=loss\n",
    "        acc_avg+=acc\n",
    "        step+=1\n",
    "        if(step%50)==0:\n",
    "            trng.set_description(\"Loss: {:.4f}\\tAcc: {:.4f}\".format(loss_avg/(step-last_step),acc_avg/(step-last_step)))\n",
    "            trng.refresh()\n",
    "            loss_avg = 0.0\n",
    "            acc_avg = 0.0\n",
    "            last_step = step\n",
    "    model.save(\"../Models/LFW_GRAYSCALE_64/Age/model-{:03d}.hdf5\".format(epoch_i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
